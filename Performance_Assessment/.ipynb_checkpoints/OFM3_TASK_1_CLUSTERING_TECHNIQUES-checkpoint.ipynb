{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OFM3 — OFM3 TASK 1: CLUSTERING TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Ryan L. Buchanan</li>\n",
    "<li>Student ID:  001826691</li>\n",
    "<li>Masters Data Analytics (12/01/2020)</li>\n",
    "<li>Program Mentor:  Dan Estes</li>\n",
    "<li>385-432-9281 (MST)</li>\n",
    "<li>rbuch49@wgu.edu</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 1\n",
    "One of the most critical factors in customer relationship management that directly affects a company’s long-term profitability is understanding its customers. When a company can better understand its customer characteristics, it is better able to target products and marketing campaigns for customers, resulting in better profits for the company in the long term.\n",
    "\n",
    "You are an analyst for a telecommunications company that wants to better understand the characteristics of its customers. You have been asked to perform a market basket analysis to analyze customer data to identify key associations of your customer purchases, ultimately allowing better business and strategic decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part I: Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>A1. Proposal of Question</b>:</span>\n",
    "Which principal variables of your customers demonstrate that they are at high risk of churn?  And, therefore, which customers will churn?\n",
    "In other words, can we better understand our customers and identify patterns unique to customers who churn using unsupervised learning data mining?\n",
    "<br>This question will be answered using the <b>K-means</b> clustering technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  Define one goal of the data analysis. Ensure that your goal is reasonable within the scope of the scenario and is represented in the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>A2. Defined Goal</b>:</span>\n",
    "Stakeholders in the company will benefit by knowing, with some measure of confidence, which customers are at highest risk of churn because this will provide weight for decisions in marketing improved services to customers with these characteristics and past user experiences.\n",
    "The goal of this data analysis is to present numerical values to company stakeholders to help them better understand their customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part II: Technique Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>B1. Explanation of Clustering Technique</b>:</span>\n",
    "    \n",
    "In k-means clustering, we are not trying to predict an outcome <i>y</i> based on an independent variable(s) <i>X</i>.  Broadly, we are trying to identify patterns in our data.  More precisely, how we identify those patterns is to build a dependent variable.  We create it in such a way that each of the values of this future dependent variable are the classes of the dependent variable <span style=\"color:orange\">(SuperDataScience)</span>.  To be clear, there is no dependent variable a priori.  \n",
    "\n",
    "So, we are trying to \"cluster\" our customers in groups based on features for which they share common values, in this case, say income, bandwidth used yearly or tenure with the company, perhaps.  And, as Jeffares concludes, \"\\[a\\] good clustering solution is one that finds clusters such that the observations within each cluster are more similar than the clusters themselves\" <span style=\"color:orange\">(Jeffares, p. 1)</span>.\n",
    "\n",
    "The two clustering techniques given on this task are hierarchical & k-means.  A DataCamp tutorial points out that \"\\[a\\] critical drawback of hierarchical clustering \\[is\\] runtime\" <span style=\"color:orange\">(Daityari, p. 1)</span>. While the dataset we are analyzing is not particularly large, the machine I am using is not particularly new, either.  This is one reason we are using the k-means algorithm. \n",
    "\n",
    "Also, we considered the dataset size and its patterns in order to decide on the k-means over hierarchical.  After all, customer churn is not separating countries soccer matches or about building a dendrogram.  What we need to demonstrate to stakeholders is which groups (clusters) of customers are similar.  And, of course, how similar/different and tightly/loosely clustered are our groups of customers (market segments).\n",
    "\n",
    "This step is the exploratory phase of analysis.  Some trial and error is considered acceptable at this point in the project.  \n",
    "\n",
    "Finally, we do expect to see outcomes such that those customers who have churned may or may not have shorter tenures with the company or perhaps have used fewer of the offered telecom services.  Perhaps we may discover that, using the results of the survey, customers who churned were less satisfied and rated the company's customer service accordingly, while those customers who remained loyal rated customer service more satisfactorily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>B2. Summary of Technique Assumption</b>:</span>\n",
    "\n",
    "Our key assumption in K-means clustering is, as VanderPlas points out, that the centroid or \"cluster center\" is the arithmetic mean of all points within or \"belonging to\" a cluster <span style=\"color:orange\">(VanderPlas, p. 463)</span>.\n",
    "\n",
    "Jeffares demonstrates that \"we wish to find the centroid <i>C</i> that minimises\" the distortion.\n",
    "    \n",
    "Where the distortion is measure of the variability of the observations within each cluster, also called the Within Cluster Sum of Squares (WCSS), <i>J</i>(<i>x</i>) is:\n",
    "\n",
    "$ J(x) = \\sum \\limits _{i=1} ^{m} || x_{i} - C || ^2 $\n",
    "\n",
    "\n",
    "Given the centroid <i>C</i>:  \n",
    "\n",
    "\n",
    "$ C = \\frac {\\sum \\limits _{i=1} ^{m} \\ x_{i}}{ m} $\n",
    "\n",
    "\n",
    "<span style=\"color:orange\">(Jeffares, p. 1).</span>\n",
    "\n",
    "<span style=\"color:red\">\"The centroids have stabilized — there is no change in their values because the clustering has been successful.\n",
    "The defined number of iterations has been achieved.\"\n",
    "https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1#:~:text=The%20centroids%20have,has%20been%20achieved.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>B3. Packages or Libraries List</b>:</span>\n",
    "\n",
    "The packages or libraries I have chosen for Python include:\n",
    "* Pandas\n",
    "* Numpy\n",
    "* Matplotlib\n",
    "* Seaborn\n",
    "* Scikit-learn\n",
    "* Scipy\n",
    "\n",
    "<br>Pandas, Numpy & Matplotlib are considered standard imports in a data science project, providing methods & statistical packages for reading, scoring & visualizing the data.  More specifically, \"Pandas for reading and writing spreadsheets, Numpy for carrying out efficient computations, \\[and\\]\n",
    "Matplotlib for visualization of data\" (Garbade, p. 1). The Seaborn package provides more descriptive & visually intuitive graphs, matrices & plots.  The Scikit-learn packages efficiently implements methods for splitting, fitting, predicting & applying metrics for many machine learning models. Scipy offers a library for the kmeans algorithm and its methods as well as methods for scaling and normalization.\n",
    "\n",
    "<br>Also, IPython Jupyter notebooks will be used to support this analysis.  Python offers very intuitive, simple & versatile programming style & syntax, as well as a large system of mature packages for data science & machine learning.  Since, Python is cross-platform, it will work well whether consumers of the analysis are using Windows PCs or a MacBook laptop.  It is fast when compared with other possible programming languages like R or MATLAB <span style=\"color:orange\">(Massaron, p. 8)</span>.\n",
    "\n",
    "<br>Also, there is strong support for Python as the most popular data science programming language in popular literature & media <span style=\"color:orange\">(CBTNuggets, p. 1)</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>C1. Data Preprocessing</b>:</span>\n",
    "\n",
    "<span style=\"color:red\">A key preprocessing goal we need to consider is ....</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>C2. Dataset Variables</b>:</span>\n",
    "Initial dataset variables used to perform the analysis are identified and classified as continuous or categorical below.\n",
    "\n",
    "The matrix of features (columns we want to keep to identify patterns) includes all features, accept the four columns of identifying numbers at the beginning of the csv.  Those will be removed during the cleaning process.\n",
    "\n",
    "However, for purposes of visualization we will use Tenure, Churn, Bandwidth_GB_Year and MonthlyCharge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>C3. Steps for Analysis</b>:</span>\n",
    "The steps used to prepare the dataset will include:\n",
    "<br>&ensp; 1. Back up my data and the process I am following as a copy to my machine and, since this is a manageable dataset, to GitHub using command line and gitbash.\n",
    "<br>&ensp; 2. Read the dataset into a Python DataFrame using Pandas' read_csv command.\n",
    "<br>&ensp; 3. Evaluate the data structure to better understand input data using info() & describe() methods.\n",
    "<br>&ensp; 4. Naming the dataset as a the variable \"churn_df\" & subsequent useful slices of the dataframe as \"df\".\n",
    "<br>&ensp; 5. Examine potential misspellings, awkward variable naming and missing data.\n",
    "<br>&ensp; 6. Explore descriptive statistics for outliers that may create or hide statistical significance using histograms, box plots and scatter plots.\n",
    "<br>&ensp; 7. Where necessary, impute records missing data with meaningful measures of central tendency (mean, median or mode) or simply remove outliers that are several standard deviations above the mean.\n",
    "<br>&ensp; 8. Remove less meaningful categorical variables from dataset to provide fully numerical dataframe for further analysis.\n",
    "<br>&ensp; 9. Extract cleaned dataset as \"churn_prepared_kmeans.csv\" for use in K-means clustering model.\n",
    "\n",
    "Most relevant to our decision making process is the <b>dependent variable</b> of \"Churn\" which is binary and categorical with only two values, \"Yes\" or \"No\".  \"Churn\" will be our <b>categorical target variable</b>, our <b><i>y</i></b>. \n",
    "\n",
    "<br>In cleaning the data, we may discover relevance in the following <b>continuous predictor variables</b>: \n",
    "* Children\n",
    "* Age\n",
    "* Income\n",
    "* Outage_sec_perweek\n",
    "* Email\n",
    "* Contacts    \n",
    "* Yearly_equip_failure\n",
    "* Tenure (the number of months the customer has stayed with the provider)\n",
    "* MonthlyCharge\n",
    "* Bandwidth_GB_Year    \n",
    "    \n",
    "<br>Likewise, we may discover the relevance of the <b>categorical predictor variables</b> (all binary categorical with only two values, \"Yes\" or \"No\", except where noted). The following will be encoded as dummy variables with 1/0: \n",
    "* Techie: Whether the customer considers themselves technically inclined (based on\n",
    "customer questionnaire when they signed up for services) (yes, no)\n",
    "* Contract: The contract term of the customer (month-to-month, one year, two year)\n",
    "* Port_modem: Whether the customer has a portable modem (yes, no)\n",
    "* Tablet: Whether the customer owns a tablet such as iPad, Surface, etc. (yes, no)\n",
    "* InternetService: Customer’s internet service provider (DSL, fiber optic, None)\n",
    "* Phone: Whether the customer has a phone service (yes, no)\n",
    "* Multiple: Whether the customer has multiple lines (yes, no)\n",
    "* OnlineSecurity: Whether the customer has an online security add-on (yes, no)\n",
    "* OnlineBackup: Whether the customer has an online backup add-on (yes, no)\n",
    "* DeviceProtection: Whether the customer has device protection add-on (yes, no)\n",
    "* TechSupport: Whether the customer has a technical support add-on (yes, no)\n",
    "* StreamingTV: Whether the customer has streaming TV (yes, no)\n",
    "* StreamingMovies: Whether the customer has streaming movies (yes, no)\n",
    "    \n",
    "<br>Finally, our <b>discrete ordinal predictor variables</b> from survey responses of customers regarding various customer service features may be relevant in the decision-making process. In the surveys, customers provided ordinal numerical data by rating eight customer service factors on a scale of 1 to 8 (1 = most important, 8 = least important): \n",
    "    \n",
    "* Item1: Timely response\n",
    "* Item2: Timely fixes\n",
    "* Item3: Timely replacements\n",
    "* Item4: Reliability\n",
    "* Item5: Options\n",
    "* Item6: Respectful response\n",
    "* Item7: Courteous exchange\n",
    "* Item8: Evidence of active listening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Scipy\n",
    "from scipy.cluster.vq import kmeans, vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change color of Matplotlib font\n",
    "import matplotlib as mpl\n",
    "\n",
    "COLOR = 'white'\n",
    "mpl.rcParams['text.color'] = COLOR\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "mpl.rcParams['xtick.color'] = COLOR\n",
    "mpl.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase Jupyter display cell-width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore Warning Code\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set into Pandas dataframe\n",
    "churn_df = pd.read_csv('data/churn_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an idea of dataset size\n",
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examine the features of the dataset\n",
    "churn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DataFrame info\n",
    "churn_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data types of features\n",
    "churn_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine first few records of dataset\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an overview of descriptive statistics\n",
    "churn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove less relevant categorical variables from dataset\n",
    "churn_df = churn_df.drop(columns=['CaseOrder', 'Customer_id', 'Interaction', 'UID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename last 8 survey columns for better description of variables\n",
    "churn_df.rename(columns = {'Item1':'TimelyResponse', \n",
    "                    'Item2':'Fixes', \n",
    "                     'Item3':'Replacements', \n",
    "                     'Item4':'Reliability', \n",
    "                     'Item5':'Options', \n",
    "                     'Item6':'Respectfulness', \n",
    "                     'Item7':'Courteous', \n",
    "                     'Item8':'Listening'}, \n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review changes\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create histograms of contiuous variables & categorical variables\n",
    "churn_df[['Children', 'Age', 'Income', 'Outage_sec_perweek', 'Email', \n",
    "          'Contacts', 'Yearly_equip_failure', 'Tenure', 'MonthlyCharge', \n",
    "          'Bandwidth_GB_Year', 'TimelyResponse', 'Courteous']].hist()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style to ggplot for aesthetics & R style\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a scatter matrix of numeric variables for high level overview of potential relationships & distributions\n",
    "churn_numeric = churn_df[['Children', 'Age', 'Income', 'Outage_sec_perweek', \n",
    "                          'Email', 'Contacts','Yearly_equip_failure', 'Tenure', \n",
    "                          'MonthlyCharge', 'Bandwidth_GB_Year', 'Replacements', \n",
    "                          'Reliability', 'Options', 'Respectfulness', 'Courteous', \n",
    "                          'Listening']]\n",
    "\n",
    "\n",
    "scatter_matrix = pd.plotting.scatter_matrix(\n",
    "    churn_numeric,\n",
    "    figsize  = [15, 15],\n",
    "    diagonal = \"kde\",\n",
    "    color=\"b\"\n",
    ")\n",
    "\n",
    "for ax in scatter_matrix.ravel():\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize = 10, rotation = 90)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize = 10, rotation = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot to get an idea of correlations between potentially related variables\n",
    "sns.scatterplot(x=churn_df['Tenure'], y=churn_df['Churn'], color='blue')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a scatterplot to get an idea of correlations between potentially related variables\n",
    "sns.scatterplot(x=churn_df['MonthlyCharge'], y=churn_df['Outage_sec_perweek'], color='blue')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a scatterplot to get an idea of correlations between potentially related variables\n",
    "sns.scatterplot(x=churn_df['Tenure'], y=churn_df['Bandwidth_GB_Year'], color='blue')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot more useful than scatter_matrix when features of dataset are binary\n",
    "plt.figure()\n",
    "sns.countplot(x='Techie', hue='Churn', data=churn_df, palette='RdBu')\n",
    "plt.xticks([0,1], ['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Countplot more useful than scatter_matrix when features of dataset are binary\n",
    "plt.figure()\n",
    "sns.countplot(x='PaperlessBilling', hue='Churn', data=churn_df, palette='RdBu')\n",
    "plt.xticks([0,1], ['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot more useful than scatter_matrix when features of dataset are binary\n",
    "plt.figure()\n",
    "sns.countplot(x='InternetService', hue='Churn', data=churn_df, palette='RdBu')\n",
    "plt.xticks([0,1], ['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Seaborn boxplots for continuous & categorical variables\n",
    "sns.boxplot('Age', data = churn_df, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find exact Age range in column\n",
    "print(\"Minimum Age is\", churn_df.Age.min())\n",
    "print(\"Maximum Age is\", churn_df.Age.max())\n",
    "print(\"Age range is\", churn_df.Age.max()-churn_df.Age.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exact Income range in column\n",
    "print(\"Minimum Income is\", int(churn_df.Income.min()))\n",
    "print(\"Maximum Income is\", int(churn_df.Income.max()))\n",
    "print(\"Income range is\", int(churn_df.Income.max()-churn_df.Income.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Seaborn boxplots for continuous & categorical variables\n",
    "sns.boxplot('MonthlyCharge', data = churn_df, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exact MonthlyCharge range in column\n",
    "print(\"Minimum MonthlyCharge is\", int(churn_df.MonthlyCharge.min()))\n",
    "print(\"Maximum MonthlyCharge is\", int(churn_df.MonthlyCharge.max()))\n",
    "print(\"MonthlyCharge range is\", int(churn_df.MonthlyCharge.max()-churn_df.MonthlyCharge.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Seaborn boxplots for continuous & categorical variables\n",
    "sns.boxplot('Bandwidth_GB_Year', data = churn_df, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Seaborn boxplots for continuous variables\n",
    "sns.boxplot('Tenure', data = churn_df, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anomalies\n",
    "It appears that anomolies have been removed from the supplied dataset, churn_clean.csv. &nbsp; There are no remaining outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover missing data points within dataset\n",
    "data_nulls = churn_df.isnull().sum()\n",
    "print(data_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data & visualize missing values in dataset \n",
    "\n",
    "# Install appropriate library\n",
    "!pip install missingno\n",
    "\n",
    "# Importing the libraries\n",
    "import missingno as msno\n",
    "\n",
    "# Visualize missing values as a matrix\n",
    "msno.matrix(churn_df);\n",
    "\"\"\"(GeeksForGeeks, p. 1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode binary categorical variables with dummies\n",
    "churn_df['DummyGender'] = [1 if v == 'Male' else 0 for v in churn_df['Gender']]\n",
    "churn_df['DummyChurn'] = [1 if v == 'Yes' else 0 for v in churn_df['Churn']] ### If the customer left (churned) they get a '1'\n",
    "churn_df['DummyTechie'] = [1 if v == 'Yes' else 0 for v in churn_df['Techie']]\n",
    "churn_df['DummyContract'] = [1 if v == 'Two Year' else 0 for v in churn_df['Contract']]\n",
    "churn_df['DummyPort_modem'] = [1 if v == 'Yes' else 0 for v in churn_df['Port_modem']]\n",
    "churn_df['DummyTablet'] = [1 if v == 'Yes' else 0 for v in churn_df['Tablet']]\n",
    "churn_df['DummyInternetService'] = [1 if v == 'Fiber Optic' else 0 for v in churn_df['InternetService']]\n",
    "churn_df['DummyPhone'] = [1 if v == 'Yes' else 0 for v in churn_df['Phone']]\n",
    "churn_df['DummyMultiple'] = [1 if v == 'Yes' else 0 for v in churn_df['Multiple']]\n",
    "churn_df['DummyOnlineSecurity'] = [1 if v == 'Yes' else 0 for v in churn_df['OnlineSecurity']]\n",
    "churn_df['DummyOnlineBackup'] = [1 if v == 'Yes' else 0 for v in churn_df['OnlineBackup']]\n",
    "churn_df['DummyDeviceProtection'] = [1 if v == 'Yes' else 0 for v in churn_df['DeviceProtection']]\n",
    "churn_df['DummyTechSupport'] = [1 if v == 'Yes' else 0 for v in churn_df['TechSupport']]\n",
    "churn_df['DummyStreamingTV'] = [1 if v == 'Yes' else 0 for v in churn_df['StreamingTV']]\n",
    "churn_df['StreamingMovies'] = [1 if v == 'Yes' else 0 for v in churn_df['StreamingMovies']]\n",
    "churn_df['DummyPaperlessBilling'] = [1 if v == 'Yes' else 0 for v in churn_df['PaperlessBilling']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop original categorical features from dataframe\n",
    "churn_df = churn_df.drop(columns=['Gender', 'Churn', 'Techie', 'Contract', 'Port_modem', 'Tablet', \n",
    "                                  'InternetService', 'Phone', 'Multiple', 'OnlineSecurity', \n",
    "                                  'OnlineBackup', 'DeviceProtection', 'TechSupport', \n",
    "                                  'StreamingTV', 'StreamingMovies', 'PaperlessBilling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List features for analysis\n",
    "features = (list(churn_df.columns[:-1]))\n",
    "print('Features for analysis include: \\n', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>C4. Cleaned Dataset</b>:</span>\n",
    "Cleaned dataset is extracted as \"churn_prepared_kmeans.csv.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Clean dataset\n",
    "churn_df.to_csv('data/churn_prepared_kmeans.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part IV: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>D1. Output and Intermediate Calculations</b></span>\n",
    "We used the Scikit-learn KMeans class to iterate over three sets of paired relevant features in order to provide meaningful heuristics from which better understand our customers and, therefore, make better business desicions. Those three sets included:\n",
    "\n",
    "* Tenure and MonthlyCharge\n",
    "* Income and MonthlyCharge \n",
    "* Tenure and Bandwidth_GB_Year\n",
    "\n",
    "To find optimal numbers of clusters, we used the scree plot elbow method for each set, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>D2. Code Execution</b></span>\n",
    "K-means clustering code and visualizations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prepared Churn dataset\n",
    "churn_df = pd.read_csv('data/churn_prepared_kmeans.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans class from Scikit-learn\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style to ggplot for aesthetics & R style\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\"><b>K-means: Tenure v. MonthlyCharge</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select indexes (features) of Tenure and MonthlyCharge for initial clustering\n",
    "X = churn_df.iloc[:, [35, 36]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the elbow method to find the optimal number of clusters\n",
    "# Create a Within Cluster Sum of Squares (WCSS) list\n",
    "wcss = []\n",
    "\n",
    "# Write a for loop to write values to wcss list by iterating through kmeans objects\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Scree plot the optimal number of clusters\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.savefig('churn_scree_tenure_v_monthly-charge.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the K-means model on the dataset\n",
    "kmeans = KMeans(n_clusters=6, init='k-means++', random_state=42)\n",
    "\n",
    "# Build the dependent variable to split customers in different clusters\n",
    "y_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "# Scatter plot 5 clusters for Tenure v. MonthlyCharge\n",
    "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 10, c = 'red', label = 'cluster 1')\n",
    "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 10, c = 'green', label = 'cluster 2')\n",
    "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 10, c = 'blue', label = 'cluster 3')\n",
    "plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 10, c = 'orange', label = 'cluster 4')\n",
    "plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 10, c = 'cyan', label = 'cluster 5')\n",
    "plt.scatter(X[y_kmeans == 5, 0], X[y_kmeans == 5, 1], s = 10, c = 'magenta', label = 'cluster 6')\n",
    "\n",
    "# Plot centroids of each cluster\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 100, c = 'yellow', label = 'Centroids')\n",
    "\n",
    "# Generate plot description\n",
    "title_obj = plt.title('6 Clusters of Customers') #get the title property handler\n",
    "plt.getp(title_obj)                  #print out the properties of title\n",
    "plt.getp(title_obj, 'text')            #print out the 'text' property for title\n",
    "plt.setp(title_obj, color='gray')         #set the color of title to red\n",
    "\n",
    "plt.xlabel('Tenure (months)')\n",
    "plt.ylabel('MonthlyCharge $')\n",
    "\n",
    "# Color of legend font\n",
    "legend = plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.setp(legend.get_texts(), color='gray')\n",
    "\n",
    "# Save plot to directory\n",
    "plt.savefig('churn_kmeans_tenure_v_monthly-charge.jpg')\n",
    "\n",
    "# Plot it\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\"><b>K-means: Income v. MonthlyCharge</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select indexes (features) of Income and MonthlyCharge for initial clustering\n",
    "X = churn_df.iloc[:, [12, 36]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the elbow method to find the optimal number of clusters\n",
    "# Create a Within Cluster Sum of Squares (WCSS) list\n",
    "wcss = []\n",
    "\n",
    "# Write a for loop to write values to wcss list by iterating through kmeans objects\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Scree plot the optimal number of clusters\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.savefig('churn_scree_income_v_monthly-charge.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the K-means model on the dataset\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "\n",
    "# Build the dependent variable to split customers in different clusters\n",
    "y_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "# Scatter plot 4 clusters for Income and MonthlyCharge\n",
    "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 10, c = 'red', label = 'cluster 1')\n",
    "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 10, c = 'green', label = 'cluster 2')\n",
    "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 10, c = 'blue', label = 'cluster 3')\n",
    "plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 10, c = 'orange', label = 'cluster 4')\n",
    "\n",
    "# Plot centroids of each cluster\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 100, c = 'yellow', label = 'Centroids')\n",
    "\n",
    "# Generate plot description\n",
    "title_obj = plt.title('4 Clusters of Customers') #get the title property handler\n",
    "plt.getp(title_obj)                  #print out the properties of title\n",
    "plt.getp(title_obj, 'text')            #print out the 'text' property for title\n",
    "plt.setp(title_obj, color='gray')         #set the color of title to red\n",
    "\n",
    "plt.xlabel('Income $')\n",
    "plt.ylabel('MonthlyCharge $')\n",
    "\n",
    "# Color of legend font\n",
    "legend = plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.setp(legend.get_texts(), color='gray')\n",
    "\n",
    "# Save plot to directory\n",
    "plt.savefig('churn_kmeans_income_v_monthly-charge.jpg')\n",
    "\n",
    "# Plot it\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\"><b>K-means: Tenure v. Bandwidth_GB_Year</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select indexes (features) of Tenure and Bandwidth_GB_Year for initial clustering\n",
    "X = churn_df.iloc[:, [35, 37]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the elbow method to find the optimal number of clusters\n",
    "# Create a Within Cluster Sum of Squares (WCSS) list\n",
    "wcss = []\n",
    "\n",
    "# Write a for loop to write values to wcss list by iterating through kmeans objects\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Scree plot the optimal number of clusters\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.savefig('churn_scree_tenure_v_bandwidth-gb-year.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the K-means model on the dataset\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++', random_state=42)\n",
    "\n",
    "# Build the dependent variable to split customers in different clusters\n",
    "y_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "# Scatter plot 4 clusters for Tenure and Bandwidth_GB_Year\n",
    "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 10, c = 'red', label = 'cluster 1')\n",
    "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 10, c = 'green', label = 'cluster 2')\n",
    "\n",
    "# Plot centroids of each cluster\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 100, c = 'yellow', label = 'Centroids')\n",
    "\n",
    "# Generate plot description\n",
    "title_obj = plt.title('2 Clusters of Customers') #get the title property handler\n",
    "plt.getp(title_obj)                  #print out the properties of title\n",
    "plt.getp(title_obj, 'text')            #print out the 'text' property for title\n",
    "plt.setp(title_obj, color='gray')         #set the color of title to red\n",
    "\n",
    "plt.xlabel('Tenure (months)')\n",
    "plt.ylabel('Bandwidth_GB_Year')\n",
    "\n",
    "# Color of legend font\n",
    "legend = plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.setp(legend.get_texts(), color='gray')\n",
    "\n",
    "# Save plot to directory\n",
    "plt.savefig('churn_kmeans_tenure_v_bandwidth-gb-year.jpg')\n",
    "\n",
    "# Plot it\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part V: Data Summary and Implications\n",
    "E.  Summarize your data analysis by doing the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>E1. Accuracy of Clustering Technique</b></span>\n",
    "<span style=\"color:red\">Explain the accuracy of your clustering technique.</span>\n",
    "\n",
    "As Manimaran suggests at TowardsDataScience.com, \"Validating the clustering algorithm is bit tricky compared to supervised machine learning algorithm as clustering process does not contain ground truth labels\" (Manimaran, p. 1). \n",
    "\n",
    "So, we will consider three factors in evaluating the accuracy of our k-means clustering here:\n",
    "\n",
    "* Clustering tendency\n",
    "* Number of clusters\n",
    "* Clustering quality\n",
    "\n",
    "Though many of our potential numerical variables contain uniformly distributed data points, as is demonstrated with our scatter matrix above (see bivariate plots including customer survey results - ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas cross-tabulation class???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>E2. Results and Implications</b></span>\n",
    "<span style=\"color:red\">Discuss the results and implications of your clustering analysis.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>E3. Limitation</b></span>\n",
    " <span style=\"color:red\">Discuss <b><i>one</i></b> limitation of your data analysis. . . . <b><i>Random initialization trap?</i></b></span>\n",
    "\n",
    "\"When using the k-nearest neighbors algorithm you have the ability to change k, potentially yielding dramatically different results. You choose the value of <b><i>k</i></b> by trying different values and testing the prediction capabilities of the model. This means you must develop, validate, and test several models\" <span style=\"color:orange\">(Grant, pg. 1).</span>\n",
    "<br>What this means to our analysis here is that the relatively arbitrary choice of <b><i>k</i></b> = 7 nearest neighbors might yield dramatically different results if we chose a different <b><i>k</i></b> number of neighbors.  As discovered in our cross validation grid search, perhaps it should be the 6 nearest neighbors.\n",
    "Also, it appears to be memory intensive & computationally expensive.  Therefore, simply, it takes a long time to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>E4. Course of Action</b></span>\n",
    "<span style=\"color:red\">Recommend a course of action for the real-world organizational situation from part A1 based on your results and implications discussed in part E2.</span>\n",
    "    \n",
    "&emsp; It is critical that decision-makers & marketers understand that our predictor variables create a relatively low accuracy score with the results of an 0.84 after scaling. &nbsp; We should analyse the features that are in common among those leaving the company & attempt to reduce their likelihood of occuring with any given customer in the future. &nbsp; This suggests that as a customer subscribes to more services that the company provided, an additional port modem or online backup for example, they are less likely to leave the company. &nbsp; Clearly, it is the best interest of retaining customers to provide them with more services & improve their experience with the company by helping customers understand all the services that are available to them as a subscriber, not simple mobile phone service. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"><b>F. Video</b></span>\n",
    "<span style=\"color:red\">link</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G. Sources for Third-Party Code\n",
    "* GeeksForGeeks. &ensp; (2019, July 4). &ensp; <i>Python | Visualize missing values (NaN) values using Missingno Library</i>. &ensp; GeeksForGeeks. &ensp; https://www.geeksforgeeks.org/python-visualize-missing-values-nan-values-using-missingno-library/\n",
    "<br>\n",
    "* SuperDataScience. &ensp; (2021, August 15) &ensp; <i>Machine Learning A-Z: Hands-On Python & R in Data Science</i>. &ensp; https://www.superdatascience.com/\n",
    "<br>\n",
    "<!-- * Dennis, T. &ensp; (2019, July 25). &ensp; <i>Confusion Matrix Visualization</i>. &ensp; Medium. &ensp; https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H. Sources \n",
    "* CBTNuggets. &ensp; (2018, September 20). &ensp; <i>Why Data Scientists Love Python</i>. &ensp; CBTNuggets. &ensp; https://www.cbtnuggets.com/blog/technology/data/why-data-scientists-love-python\n",
    "<br> \n",
    "* Daityari, S. &ensp; (2021, October 03). &ensp; <i>Basics of k-means clustering</i>. &ensp; DataCamp. &ensp; https://campus.datacamp.com/courses/cluster-analysis-in-python/k-means-clustering-3?ex=1\n",
    "<br>\n",
    "* Garbade, M. &ensp; (2018, September 12). &ensp; <i>Understanding K-means Clustering in Machine Learning</i>. &ensp; TowardDataScience. &ensp; https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1\n",
    "<br> \n",
    "* Jeffares, A. &ensp; (2019, November 19). &ensp; <i>K-means: A Complete Introduction</i>. &ensp; TowardDataScience. &ensp; https://towardsdatascience.com/k-means-a-complete-introduction-1702af9cd8c\n",
    "<br> \n",
    "* Manimaran. &ensp; (2019, May 22). &ensp; <i>Clustering Evaluation Strategies</i>. &ensp; TowardDataScience. &ensp; https://towardsdatascience.com/clustering-evaluation-strategies-98a4006fcfc\n",
    "<br>\n",
    "* Massaron, L. & Boschetti, A. &ensp; (2016). &ensp; <i>Regression Analysis with Python</i>. &ensp; Packt Publishing.\n",
    "<br> \n",
    "* VanderPlas, J. &ensp; (2017). &ensp; <i>Python Data Science Handbook</i>. &ensp; O'Reilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
    "from colab_pdf import colab_pdf\n",
    "colab_pdf('OFM3_TASK_1_CLUSTERING_TECHNIQUES.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
